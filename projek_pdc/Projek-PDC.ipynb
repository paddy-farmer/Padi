{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import skimage.io\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.exposure import equalize_adapthist\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "from rembg.bg import remove\n",
    "import io\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# print(os.listdir(\"rice_leaf_diseases\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "print(ort.get_device())\n",
    "# model_path = '<path to model>'\n",
    "\n",
    "# providers = [\n",
    "#     ('CUDAExecutionProvider', {\n",
    "#         'device_id': 0,\n",
    "#         'arena_extend_strategy': 'kNextPowerOfTwo',\n",
    "#         'gpu_mem_limit': 2 * 1024 * 1024 * 1024,\n",
    "#         'cudnn_conv_algo_search': 'EXHAUSTIVE',\n",
    "#         'do_copy_in_default_stream': True,\n",
    "#     }),\n",
    "#     'CPUExecutionProvider',\n",
    "# ]\n",
    "\n",
    "# session = ort.InferenceSession(model_path, providers=providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path folder penyakit\n",
    "ori_blb_path = \"rice_leaf_diseases/train/bacterial_leaf_blight/\"\n",
    "ori_bs_path = \"rice_leaf_diseases/train/brown_spot/\"\n",
    "ori_ls_path = \"rice_leaf_diseases/train/leaf_smut/\"\n",
    "\n",
    "# path setelah color balanced\n",
    "blb_cb = \"rld_img_cb/blb/\"\n",
    "bs_cb = \"rld_img_cb/bs/\"\n",
    "ls_cb = \"rld_img_cb/ls/\"\n",
    "\n",
    "# path setelah rembg\n",
    "r_blb_path = \"rld_img_rembg/blb/\"\n",
    "r_bs_path = \"rld_img_rembg/bs/\"\n",
    "r_ls_path = \"rld_img_rembg/ls/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcorrect.algorithm as cca\n",
    "from colorcorrect.util import from_pil, to_pil\n",
    "\n",
    "img_test = Image.open(ori_blb_path + '/' + \"DSC_0365.JPG\")\n",
    "# to_pil(cca.max_white(from_pil(img_test))).show()\n",
    "\n",
    "def colorBalance(image, name, path):\n",
    "    \"\"\"\n",
    "    Implement cca.max_white color correction algorithm \n",
    "      using colorcorrect library\n",
    "    Args:\n",
    "        image: image object that will be color balanced\n",
    "        name: filename of the saved color balanced image\n",
    "        path: color balanced image destination folder\n",
    "    Returns: \n",
    "    \"\"\"\n",
    "\n",
    "    to_pil(cca.max_white(from_pil(image))).save(path + name)\n",
    "\n",
    "\n",
    "# colorBalance(img_test, \"DSC_0365.JPG\", r_blb_cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessedImage(img_path, rmv_bg_img_path):\n",
    "    \"\"\"\n",
    "    Remove background from image using rembg library\n",
    "    Args:\n",
    "        img_path: path of the image folder directory in string\n",
    "        rmv_bg_img_path: destination of removed background path\n",
    "    Returns: \n",
    "    \"\"\"\n",
    "    os_path = os.listdir(img_path)\n",
    "    for img_name in os_path[:]:\n",
    "        read_img = cv2.imread(img_path + img_name) #read image from path\n",
    "        read_img = cv2.cvtColor(read_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        r_bg_img = remove(read_img)\n",
    "\n",
    "        cv2.imwrite(rmv_bg_img_path + img_name, r_bg_img)\n",
    "\n",
    "        \n",
    "#function display all images\n",
    "def displayImg(array):\n",
    "    \"\"\"\n",
    "    Display all images from an array\n",
    "    Args:\n",
    "        array: array that contains image data type\n",
    "    Returns: Image displayed using matlotlib\n",
    "    \"\"\"\n",
    "    n = len(array)\n",
    "    # f = plt.figure()\n",
    "    for i in range(n):\n",
    "        plt.figure()\n",
    "        plt.imshow(array[i])\n",
    "        plt.show(block = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedImage(ori_blb_path, r_blb_path)\n",
    "# preprocessedImage(ori_bs_path, r_bs_path)\n",
    "# preprocessedImage(ori_ls_path, r_ls_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getRGB(event,x,y,flags,param): #(Based from stackoverflow by Wicaledon to get RGB color values from clicked pixel of an image)\n",
    "#     if event == cv2.EVENT_LBUTTONDOWN: #checks mouse left button down condition\n",
    "#         colorsR = image[y,x,2]\n",
    "#         colorsG = image[y,x,1]\n",
    "#         colorsB = image[y,x,0]\n",
    "#         colors = image[y,x]\n",
    "#         print(\"RGB Format: \",colors)\n",
    "#         print(\"Pixel Coordinates: X: \",x,\"Y: \",y)\n",
    "\n",
    "# image = cv2.imread(\"rice_leaf_diseases/bacterial_leaf_blight/DSC_0365.jpg\")\n",
    "# cv2.namedWindow('getRGB')\n",
    "# cv2.setMouseCallback('getRGB',getRGB)\n",
    "\n",
    "# #Do until esc pressed\n",
    "# while(1):\n",
    "#     cv2.imshow('getRGB',image)\n",
    "#     if cv2.waitKey(20) & 0xFF == 27:\n",
    "#         break\n",
    "# #if esc pressed, finish.\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv2.imread(\"rld_img_rembg/blb/DSC_0365.JPG\") #read image from path\n",
    "x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) #convert image color to RGB\n",
    "leaf_disease_hsv = rgb2hsv(x) #convert RGB image to HSV (Based on from https://mattmaulion.medium.com/color-image-segmentation-image-processing-4a04eca25c0 by Matt Maulion)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
    "ax[0].imshow(leaf_disease_hsv[:,:,0], cmap='gray')\n",
    "ax[0].set_title('Hue')\n",
    "ax[1].imshow(leaf_disease_hsv[:,:,1], cmap='gray')\n",
    "ax[1].set_title('Saturation')\n",
    "ax[2].imshow(leaf_disease_hsv[:,:,2], cmap='gray')\n",
    "ax[2].set_title('Value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(leaf_disease_hsv[:,:,0],cmap='hsv')\n",
    "ax[0].set_title('hue')\n",
    "ax[1].imshow(leaf_disease_hsv[:,:,1],cmap='hsv')\n",
    "ax[1].set_title('transparency')\n",
    "ax[2].imshow(leaf_disease_hsv[:,:,2],cmap='hsv')\n",
    "ax[2].set_title('value')\n",
    "fig.colorbar(skimage.io.imshow(leaf_disease_hsv[:,:,0],cmap='hsv')) \n",
    "fig.colorbar(skimage.io.imshow(leaf_disease_hsv[:,:,1],cmap='hsv')) \n",
    "# fig.colorbar(imshow(leaf_disease_hsv[:,:,2],cmap='hsv')) \n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower hue \n",
    "lower_hue_mask = leaf_disease_hsv[:,:,0] > 0.487\n",
    "#upper hue\n",
    "upper_hue_mask = leaf_disease_hsv[:,:,0] < 0.65 \n",
    "#transparensi\n",
    "lower_saturation_mask = leaf_disease_hsv[:,:,1] > 0.5\n",
    "upper_saturation_mask = leaf_disease_hsv[:,:,1] < 0.8\n",
    "\n",
    " \n",
    "mask_segment = upper_hue_mask*lower_hue_mask*lower_saturation_mask*upper_saturation_mask\n",
    "# red = x[:,:,0]*mask\n",
    "# green = x[:,:,1]*mask\n",
    "# blue = x[:,:,2]*mask\n",
    "# bags_masked = np.dstack((red,green,blue))\n",
    "# imshow(bags_masked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path mask\n",
    "m_blb_path = \"rld_mask/blb\"\n",
    "m_bs_path = \"rld_mask/bs\"\n",
    "m_ls_path = \"rld_mask/ls\"\n",
    "\n",
    "\n",
    "def create_hue_mask(path1, path2, non_target_hue, target_hue):\n",
    "    \"\"\"\n",
    "    Create mask of images from path1 and save them to \n",
    "        path2y\n",
    "    Args:\n",
    "        path: path of the image folder directory in string\n",
    "        path2: path of the mask image destination\n",
    "        non-target-hue: hue value to be removed\n",
    "        target-hue: targeted hue value \n",
    "    Returns: \n",
    "    \"\"\"\n",
    "    os_path = os.listdir(path1)\n",
    "    for img in os_path[:]:\n",
    "        read_img = np.array(Image.open(path1 + \"/\" + img))\n",
    "\n",
    "        # Hue segment\n",
    "        img_hue = read_img[:,:,0]\n",
    "        markers = np.zeros_like(img_hue)\n",
    "        if non_target_hue != None:\n",
    "            markers[img_hue < non_target_hue] = 1\n",
    "        if target_hue != None:\n",
    "            markers[img_hue > target_hue] = 2\n",
    "        cmapps = [\"gray\"]\n",
    "\n",
    "        for i in range(len(cmapps)):\n",
    "            plt.imsave(path2 + \"/\" + img, markers, cmap=str(cmapps[i])) #use colormap\n",
    "\n",
    "\n",
    "def create_adp_mask(path1, path2, adp_type,  thres_type):\n",
    "    \"\"\"\n",
    "    Create mask of images from path1 and save them to \n",
    "        path2y\n",
    "    Args:\n",
    "        path: path of the image folder directory in string\n",
    "        path2: path of the mask image destination\n",
    "        adp_type: adaptive method \n",
    "        thres_type: threshold type\n",
    "    Returns: \n",
    "    \"\"\"\n",
    "    os_path = os.listdir(path1)\n",
    "    for img in os_path[:]:\n",
    "        read_img = np.array(Image.open(path1 + \"/\" + img))\n",
    "\n",
    "\n",
    "        # adapthist thresholding\n",
    "        img_gray = cv2.cvtColor(read_img, cv2.COLOR_BGR2GRAY)\n",
    "        clahe = cv2.createCLAHE(clipLimit=5)\n",
    "        clahe_img = clahe.apply(img_gray)\n",
    "        threshG = cv2.adaptiveThreshold(clahe_img, 255, adp_type, thres_type, 199, 18)\n",
    "\n",
    "        cv2.imwrite(path2 + \"/\" + img, threshG) #use colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_hue_mask(r_blb_path, m_blb_path, None, 60)\n",
    "# create_adp_mask(r_bs_path, m_bs_path, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV)\n",
    "create_adp_mask(r_ls_path, m_ls_path, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path segment img\n",
    "seg_blb_path = \"segment_img/blb\"\n",
    "seg_bs_path = \"segment_img/bs\"\n",
    "seg_ls_path = \"segment_img/ls\"\n",
    "\n",
    "def segment_disease(path_r, path_m, path_res):\n",
    "    \"\"\"\n",
    "    Segment disease from the paddy leaf\n",
    "    Args:\n",
    "        path_r: path of the removed background image\n",
    "        path_m: path of the mask image \n",
    "        path_res: destination path of segment image\n",
    "    Returns: \n",
    "    \"\"\"\n",
    "    os_path = os.listdir(path_r)\n",
    "    for img in os_path[:]:\n",
    "        r_img = cv2.imread(path_r + \"/\" + img)\n",
    "        r_img = cv2.cvtColor(r_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        m_img = cv2.imread(path_m + \"/\" + img)\n",
    "\n",
    "        res = cv2.bitwise_and(r_img, m_img)\n",
    "        cv2.imwrite(path_res + \"/\" + img, res)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment_disease(r_blb_path, m_blb_path, seg_blb_path)\n",
    "# segment_disease(r_bs_path, m_bs_path, seg_bs_path)\n",
    "segment_disease(r_ls_path, m_ls_path, seg_ls_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"rice_leaf_diseases/\"\n",
    "\n",
    "train_data = datasets.ImageFolder(data_dir + '/train')\n",
    "val_data = datasets.ImageFolder(data_dir + '/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data,)\n",
    "\n",
    "dataiter = iter(train_data)\n",
    "images, clases = dataiter.__next__()\n",
    "print(type(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "val_transforms = transforms.Compose([transforms.ToTensor(),])\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "val_data = datasets.ImageFolder(data_dir + '/validation', transform=val_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "val_transforms = transforms.Compose([transforms.ToTensor(),])\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "val_data = datasets.ImageFolder(data_dir + '/validation', transform=val_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "class CropDetectCNN(nn.Module):\n",
    "    # initialize the class and the parameters\n",
    "    def __init__(self):\n",
    "        super(CropDetectCNN, self).__init__()\n",
    "        \n",
    "        # convolutional layer 1 & max pool layer 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        \n",
    "        # convolutional layer 2 & max pool layer 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        \n",
    "        #Fully connected layer\n",
    "        self.fc = nn.Linear(32*28*28, 39)\n",
    "         \n",
    "    # Feed forward the network\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "model = CropDetectCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on GPU if available else run on a CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1 # run more iterations\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, classes in train_loader:\n",
    "        # To device - to transfrom the image and classes to CPU|GPU\n",
    "        images, classes = images.to(device), classes.to(device)\n",
    "        \n",
    "        # clears old gradients from the last step\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # train the images\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #calculate the loss given the outputs and the classes\n",
    "        loss = criterion(outputs, classes)\n",
    "        \n",
    "        # compute the loss of every parameter\n",
    "        loss.backward()\n",
    "        \n",
    "        # apply the optimizer and its parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        #update the loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        validation_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # to make the model run faster we are using the gradients on the train\n",
    "        with torch.no_grad():\n",
    "            # specify that this is validation and not training\n",
    "            model.eval()\n",
    "            for images, classes in val_loader:          \n",
    "                # Use GPU\n",
    "                images, classes = images.to(device), classes.to(device)\n",
    "                \n",
    "                # validate the images\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # compute validation loss\n",
    "                loss = criterion(outputs, classes)\n",
    "                \n",
    "                #update loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "                # get the exponential of the outputs\n",
    "                ps = torch.exp(outputs)\n",
    "                \n",
    "                #Returns the k largest elements of the given input tensor along a given dimension.\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                \n",
    "                # reshape the tensor\n",
    "                equals = top_class == classes.view(*top_class.shape)\n",
    "                \n",
    "                # calculate the accuracy.\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        # change the mode to train for the next epochs\n",
    "        model.train()\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Valid Loss: {:.3f}.. \".format(validation_loss/len(val_loader)),\n",
    "              \"Valid Accuracy: {:.3f}\".format(accuracy/len(val_loader)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "534f3915bd2bd12bd63476915380f007aeb245ace04ea1b92519881ddb8994b8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
